{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Leveraging Mean/Target Encoding for Better Feature Engineering and Better Predictions"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The zip (postal) code you live in says a tremendous amount about you.  (At least in North America). Where you live suggests: your annual income, whether you have children, the TV shows you watch and your political leanings. \n\nIn the United States there are over 41,000 unique zip codes.  Zip codes are largely categorical.  There is some broad meaning in the first two digits of the zip code.  For example, Hawaii zip codes start with 9 and Maine zip codes start with 0.  Beyond, very general geographic information, the codes themselves really provide little value. \n\nWhat I if said that I live in 76092?   Does that really tell you much about me?   \n\nNot really.\n\nNow, if I googled that zip code.  I would find out that 76092 is Southlake, Texas.  Southlake is one of the most affluent areas of Texas.  Living in 76092 means that I probably make more than 150k a year and have a college education. \n\nMy point here is that the code itself doesn't tell us much.  We have to find creative ways to extract value from the zip code.\n\nSo, given that zip codes can tell us a great deal about the people who live in them, how do we extract this information and exploit it in a machine learning model?\n\n\nOne way to deal with categorical variables like zip codes is to split them into dummy variables.  This is what \"One Hot Encoder\" does.  When you have a categorical variable with 41,000 unique values, dummy variables really won't be much help in my experience.    Using \"One Hot Encoder\" on zip code means you'll create 40,999 new independent variables.  Jeez, what a mess!\n\n\nAnother approach is something called Mean/Target Encoding.  In full disclosure, I have used this technique for twenty-five years and I had never heard anyone call it Mean/Target Encoding until very recently.  Whatever you want to call it, it works quite well for categorical variables like zip code, NAICS, census block or any other meaningful categorical variable that has many distinct values.\n\nIn this example, I walk through a customer prospecting use case.  The company is looking to grow its customer base but has limited marketing/sales resources.  Because they don't have enough money to contact everyone in the database, they will use a predictive model to predict those prospects most likely to buy acquire their product. I will not be building a model in this notebook.  Rather, I will show you can leverage your historical data and zip code to create features that will build more predictive machine learning models.\n\nAs I write this, it is February 2020.  So, the goal is to build a model that will predict February 2020.  To do this, we will use data from 2019.  As we do our feature engineering, it is best not to use the same data you use for your model.  Doing so leads to some major causality issues and over fitting.  Instead of 2019, I will be using data from 2018 to build my features.  So, just to re-cap.  I will use 2018 data to build my features.  Use 2019 data to build a model and apply that model to current prospects in 2020.\n\nWhat if you don't have multiple years of data?  In that case, I would recommend creating a separate sample of the data set to build your features.  So, as you build your model, you would split your data into four groups.  This would include a Training, a Testing, a Validation and a Feature Building data set.\n\nAnd finally, I will be creating summaries that are specific to a customer acquisition problem, but this technique applies to pretty much everything.  For example, you could create average costs for supplier codes in health care.  Or, Out Of Business rates for certain NAICS codes.  It is important to understand the process and realize that this technique can be applied to many different situations.\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Table of contents"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "1. [Getting Setup](#setup)<br>\n    1.1 [Install Relevant Libraries](#installlibs)<br>\n    1.2 [Import Relevant Libraries](#import)<br>\n    1.3 [Load data from GitHub](#pull)<br>\n2. [Explore Data](#explore)<br>\n\n3. [Build Features](#build)<br>\n \n4. [Append Features to the Modeling Data Set](#append)<br>\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 1.0 Getting Setup <a id=\"setup\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 1.1 Install all of the relevant Python Libraries <a id=\"installlibs\"></a>"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "!pip install --upgrade numpy ",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Collecting numpy\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/9a/7d474ba0860a41f771c9523d8c4ea56b084840b5ca4092d96bdee8a3b684/numpy-1.19.1-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14.5MB 10.3MB/s eta 0:00:01\n\u001b[31mERROR: tensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\n\u001b[31mERROR: autoai-libs 1.10.5 has requirement pandas>=0.24.2, but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Found existing installation: numpy 1.15.4\n    Uninstalling numpy-1.15.4:\n      Successfully uninstalled numpy-1.15.4\nSuccessfully installed numpy-1.19.1\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": " #### 1.2 Import relevant libraries <a id=\"import\"></a>"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "\n\nimport pandas as pd\n\n\nimport numpy as np\nimport numpy.dual as dual\n\n\n\n#Un-Comment these options if you want to exapand the number of rows and columns of you see visually in the notebook.\n#pd.set_option('display.max_columns', None)\n#pd.set_option('display.max_rows', None)",
            "execution_count": 2,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "####  1.3 Pull Data from GitHub  <a id=\"pull\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!rm YEAR_2018_1.csv\n!wget https://raw.githubusercontent.com/shadgriffin/zip_code/master/YEAR_2018_1.csv",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "rm: cannot remove \u2018YEAR_2018_1.csv\u2019: No such file or directory\n--2020-08-18 13:00:14--  https://raw.githubusercontent.com/shadgriffin/zip_code/master/YEAR_2018_1.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12874808 (12M) [text/plain]\nSaving to: \u2018YEAR_2018_1.csv\u2019\n\n100%[======================================>] 12,874,808  --.-K/s   in 0.1s    \n\n2020-08-18 13:00:15 (126 MB/s) - \u2018YEAR_2018_1.csv\u2019 saved [12874808/12874808]\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!rm YEAR_2018_2.csv\n!wget https://raw.githubusercontent.com/shadgriffin/zip_code/master/YEAR_2018_2.csv",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "rm: cannot remove \u2018YEAR_2018_2.csv\u2019: No such file or directory\n--2020-08-18 13:00:18--  https://raw.githubusercontent.com/shadgriffin/zip_code/master/YEAR_2018_2.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 11339381 (11M) [text/plain]\nSaving to: \u2018YEAR_2018_2.csv\u2019\n\n100%[======================================>] 11,339,381  --.-K/s   in 0.1s    \n\n2020-08-18 13:00:19 (107 MB/s) - \u2018YEAR_2018_2.csv\u2019 saved [11339381/11339381]\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "As I mentioned earlier, we hope to build a model on data from 2019 to predict customer acquisition in 2020. To build our features, we will use data from 2018.\n\nPull in the 2018 data from Github"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd_datax = pd.read_csv(\"YEAR_2018_1.csv\")\npd_datay = pd.read_csv(\"YEAR_2018_2.csv\")\n\ndf_data_1 = pd.concat([pd_datax,pd_datay])",
            "execution_count": 5,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 2.0 Data Exporation <a id=\"explore\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_data_1.head()",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 6,
                    "data": {
                        "text/plain": "      ZIP5  HAS_CHILDREN PRIMARY_LANGUAGE    INCOME  AGE_IN_YEARS  \\\n0  76248.0           1.0          English  125000.0     43.901437   \n1  75007.0           1.0          English   87500.0     51.816564   \n2  75071.0           1.0          English   57500.0     54.231348   \n3  75089.0           1.0            Other   87500.0     39.734428   \n4  76110.0           1.0          Spanish   52500.0     51.063655   \n\n   LENGTH_OF_RESIDENCE HOME_OWNER_RENTER  CUSTOMER  CHURN  ACQ  REVENUE  YEAR  \n0                  2.0                 O         1      0    0       52  2018  \n1                  3.0                 O         1      0    0      100  2018  \n2                  7.0                 O         1      0    1      240  2018  \n3                  9.0                 O         1      0    0       72  2018  \n4                 12.0                 O         1      0    0      172  2018  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ZIP5</th>\n      <th>HAS_CHILDREN</th>\n      <th>PRIMARY_LANGUAGE</th>\n      <th>INCOME</th>\n      <th>AGE_IN_YEARS</th>\n      <th>LENGTH_OF_RESIDENCE</th>\n      <th>HOME_OWNER_RENTER</th>\n      <th>CUSTOMER</th>\n      <th>CHURN</th>\n      <th>ACQ</th>\n      <th>REVENUE</th>\n      <th>YEAR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>76248.0</td>\n      <td>1.0</td>\n      <td>English</td>\n      <td>125000.0</td>\n      <td>43.901437</td>\n      <td>2.0</td>\n      <td>O</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>52</td>\n      <td>2018</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>75007.0</td>\n      <td>1.0</td>\n      <td>English</td>\n      <td>87500.0</td>\n      <td>51.816564</td>\n      <td>3.0</td>\n      <td>O</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>100</td>\n      <td>2018</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>75071.0</td>\n      <td>1.0</td>\n      <td>English</td>\n      <td>57500.0</td>\n      <td>54.231348</td>\n      <td>7.0</td>\n      <td>O</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>240</td>\n      <td>2018</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75089.0</td>\n      <td>1.0</td>\n      <td>Other</td>\n      <td>87500.0</td>\n      <td>39.734428</td>\n      <td>9.0</td>\n      <td>O</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>72</td>\n      <td>2018</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>76110.0</td>\n      <td>1.0</td>\n      <td>Spanish</td>\n      <td>52500.0</td>\n      <td>51.063655</td>\n      <td>12.0</td>\n      <td>O</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>2018</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "This is a fairly simple data set.  Here is a description of the fields.\n\nZIP5 -- The zip code of the individual.\n\nHAS_CHILDREN -- 1 means the individual has children.  0 means they do not.\n\nPRIMARY_LANGUAGE -- The primary language of the individual.\n\nINCOME -- Income of the individual.\n\nAGE_IN_YEARS -- Age of the individual.\n\nLENGTH_OF_RESIDENCE -- Length of time the individual has resided at their current address.\n\nHOME_OWNER_RENTER - O means the individual owns their home.  \n\nCUSTOMER - indicates if the record belongs to a customer. 1 is a customer 0 is a non-customer.\n\nCHURN -- 1 means the individual canceled their product in 2018.  0 Means they did not cancel.\n\nACQ -- 1 means the individaul acquired the product in 2018.\n\nREVENUE -- Total Revenue of the Individual in 2018.\n\nYEAR -- the YEAR of the individual record.\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "It may be obvious, but the last five fields are the important ones from a feature engineering perspective.  In the next few lines of code, for each zip code we will derive the following.\n\nZIP_PENETRATION_RATE -- The percentage of individuals in a zip code who are customers.\n\nZIP_CHURN_RATE -- the churn rate of a specific zip_code\n\nZIP_AQC_RATE -- The customer acquisition rate of the zip code.\n\nZIP_AVG_REV  -- the average revenue for customers in specific zip code.\n\nZIP_MEDIAN_REV -- the median revenue for customers in a specific zip code\n\nZIP_CUSTOMERS -- The total number of customers in a specific zip code.\n\nZIP_POPULATION -- The total number of Individuals in a specific zip code.\n\nZIP_CHURNERS -- The total number of Churners in a specific zip code.\n\nZIP _REVENUE -- The total revenue in a specific zip code.\n\nBy creating these new fields, we can extract the value imbeded in zip code. \n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 3.0 Build Features <a id=\"build\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dfx=df_data_1",
            "execution_count": 7,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\n# Create churn features\nzip_churn = pd.DataFrame(dfx.groupby(['ZIP5'])['CHURN'].agg(['sum']))\nzip_churn['TOTAL']=dfx.CHURN.sum()\n\nzip_churn.columns = ['ZIP_CHURNERS','TOTAL_CHURNERS']\n\n\n#Create customer and popluation features\nzip_cust = pd.DataFrame(dfx.groupby(['ZIP5'])['CUSTOMER'].agg(['sum','count']))\nzip_cust['TOTAL_CUSTOMERS']=dfx.CUSTOMER.sum()\nzip_cust['TOTAL_POPULATION']=dfx.CUSTOMER.sum()\n\nzip_cust.columns = ['ZIP_CUSTOMERS','ZIP_POPULATION','TOTAL_CUSTOMERS','TOTAL_POPULATION']\n\n#create acquisition features\nzip_acq = pd.DataFrame(dfx.groupby(['ZIP5'])['ACQ'].agg(['sum']))\n\nzip_acq['TOTAL']=dfx.ACQ.sum()\n\nzip_acq.columns = ['ZIP_ACQUISITIONS','TOTAL_ACQUISITIONS']\n\n\n#Create Total Revenue Features\nzip_rev = pd.DataFrame(dfx.groupby(['ZIP5'])['REVENUE'].agg(['sum']))\nzip_rev['TOTAL']=dfx.REVENUE.sum()\n\nzip_rev.columns = ['ZIP_REVENUE','TOTAL_REVENUE']\n\n#create median revenue features.\ndf_cust=dfx[dfx['CUSTOMER']==1]\n\nzip_med_rev = pd.DataFrame(df_cust.groupby(['ZIP5'])['REVENUE'].agg(['median']))\nzip_med_rev['TOTAL']=df_cust.REVENUE.median()\n\nzip_med_rev.columns = ['MED_REVENUE','TOTAL_MED_REVENUE']\n",
            "execution_count": 8,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Append the features into a single data frame."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_18 = pd.concat([zip_cust,zip_acq, zip_churn, zip_rev,zip_med_rev], axis=1)\ndf_18.reset_index(level=0, inplace=True)\n",
            "execution_count": 9,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create additional features from the existing features.\n\nNote that you have to be careful of small sample sizes  when calculating averages and ratios. In this example, I only calculate a rate or average for a zip code if there are more than 100 people in the zip code.  You want to avoid situations where a metric is high or low only because the sample is small.  For example, if you have 2 people in a zip code and one is a customer, the penetration rate would be extremely high (50%).  This high number doesn't mean that the zip code is fertile grounds for prospecting.   Maybe it is.  Maybe it isn't.  If you only have two people in your sample, the statistic really has no value.\n\nLike I mentioned earlier, I only use a statistic or ratio if there are more than 100 people are in the zip code.  If there is less than 100 people, I use the global average or ratio.  Note that there is nothing magically about 100.  You should use a number that is logical and meets the needs of your business case.  I have also seen examples were people will use a weighted metric if there is a small sample size for a particular group. That is, they will take the cases in the zip code and combine with the global average/ratio in a weighted manner.  I think that is a bit over-kill, but if you floats your boat, go for it.\n\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_18['ZIP_PENETRATION_RATE'] = np.where(((df_18['ZIP_CUSTOMERS'] <100 )), (df_18['TOTAL_CUSTOMERS'])/(df_18['TOTAL_POPULATION']), (df_18['ZIP_CUSTOMERS'])/(df_18['ZIP_POPULATION']))\ndf_18['ZIP_ACQ_RATE'] = np.where(((df_18['ZIP_CUSTOMERS'] <100 )), (df_18['TOTAL_ACQUISITIONS'])/(df_18['TOTAL_POPULATION']), (df_18['ZIP_ACQUISITIONS'])/(df_18['ZIP_POPULATION']))\ndf_18['ZIP_CHURN_RATE'] = np.where(((df_18['ZIP_CUSTOMERS'] <100 )), (df_18['TOTAL_CHURNERS'])/(df_18['TOTAL_CUSTOMERS']), (df_18['ZIP_CHURNERS'])/(df_18['ZIP_CUSTOMERS']))\ndf_18['ZIP_AVG_REV'] = np.where(((df_18['ZIP_CUSTOMERS'] <100 )), (df_18['TOTAL_REVENUE'])/(df_18['TOTAL_CUSTOMERS']), (df_18['ZIP_REVENUE'])/(df_18['ZIP_CUSTOMERS']))\ndf_18['ZIP_MED_REV'] = np.where(((df_18['ZIP_CUSTOMERS'] <100 )), (df_18['TOTAL_MED_REVENUE']), (df_18['MED_REVENUE']))\n\ndf_18=df_18[['ZIP5', 'ZIP_CUSTOMERS', 'ZIP_POPULATION', 'ZIP_ACQUISITIONS', \n       'ZIP_CHURNERS', 'ZIP_REVENUE','ZIP_PENETRATION_RATE',\n       'ZIP_ACQ_RATE', 'ZIP_CHURN_RATE', 'ZIP_AVG_REV', 'ZIP_MED_REV']]\n\ndf_18.head()",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 10,
                    "data": {
                        "text/plain": "      ZIP5  ZIP_CUSTOMERS  ZIP_POPULATION  ZIP_ACQUISITIONS  ZIP_CHURNERS  \\\n0  75001.0            231             886                62            30   \n1  75002.0           1074            4636               295           182   \n2  75006.0            772            2950               182           107   \n3  75007.0           1024            4027               249           142   \n4  75009.0            149             569                28            16   \n\n   ZIP_REVENUE  ZIP_PENETRATION_RATE  ZIP_ACQ_RATE  ZIP_CHURN_RATE  \\\n0        40181              0.260722      0.069977        0.129870   \n1       179725              0.231665      0.063632        0.169460   \n2       130349              0.261695      0.061695        0.138601   \n3       174408              0.254284      0.061833        0.138672   \n4        25281              0.261863      0.049209        0.107383   \n\n   ZIP_AVG_REV  ZIP_MED_REV  \n0   173.943723        176.0  \n1   167.341713        162.0  \n2   168.845855        168.0  \n3   170.320312        166.5  \n4   169.671141        165.0  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ZIP5</th>\n      <th>ZIP_CUSTOMERS</th>\n      <th>ZIP_POPULATION</th>\n      <th>ZIP_ACQUISITIONS</th>\n      <th>ZIP_CHURNERS</th>\n      <th>ZIP_REVENUE</th>\n      <th>ZIP_PENETRATION_RATE</th>\n      <th>ZIP_ACQ_RATE</th>\n      <th>ZIP_CHURN_RATE</th>\n      <th>ZIP_AVG_REV</th>\n      <th>ZIP_MED_REV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75001.0</td>\n      <td>231</td>\n      <td>886</td>\n      <td>62</td>\n      <td>30</td>\n      <td>40181</td>\n      <td>0.260722</td>\n      <td>0.069977</td>\n      <td>0.129870</td>\n      <td>173.943723</td>\n      <td>176.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>75002.0</td>\n      <td>1074</td>\n      <td>4636</td>\n      <td>295</td>\n      <td>182</td>\n      <td>179725</td>\n      <td>0.231665</td>\n      <td>0.063632</td>\n      <td>0.169460</td>\n      <td>167.341713</td>\n      <td>162.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>75006.0</td>\n      <td>772</td>\n      <td>2950</td>\n      <td>182</td>\n      <td>107</td>\n      <td>130349</td>\n      <td>0.261695</td>\n      <td>0.061695</td>\n      <td>0.138601</td>\n      <td>168.845855</td>\n      <td>168.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75007.0</td>\n      <td>1024</td>\n      <td>4027</td>\n      <td>249</td>\n      <td>142</td>\n      <td>174408</td>\n      <td>0.254284</td>\n      <td>0.061833</td>\n      <td>0.138672</td>\n      <td>170.320312</td>\n      <td>166.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>75009.0</td>\n      <td>149</td>\n      <td>569</td>\n      <td>28</td>\n      <td>16</td>\n      <td>25281</td>\n      <td>0.261863</td>\n      <td>0.049209</td>\n      <td>0.107383</td>\n      <td>169.671141</td>\n      <td>165.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "It is easy to get lost in python code, but let's take a step back and remember our objective.  Our objective is to extract the hidden value inside a categorical variable with 41000 unique values.  That is, make a variable useful when the actual values of the variable are not useful.  That is what we have done.  For example, the value 75001 is not very useful.  Knowing, however, that the zip code 75001 has a product penetration rate of .260722 is very useful. "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 4.0 Append Features to the Modeling Data Set <a id=\"append\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now that we have created out zip code level features, we can append them to our modeling data set, 2019 data.\n\nCollect the data from GitHub"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\n!rm YEAR_2019.csv\n!wget https://raw.githubusercontent.com/shadgriffin/zip_code/master/YEAR_2019.csv\ndf_2019 = pd.read_csv(\"YEAR_2019.csv\")",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "--2020-08-18 13:01:33--  https://raw.githubusercontent.com/shadgriffin/zip_code/master/YEAR_2019.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 18917414 (18M) [text/plain]\nSaving to: \u2018YEAR_2019.csv\u2019\n\n100%[======================================>] 18,917,414  --.-K/s   in 0.1s    \n\n2020-08-18 13:01:33 (122 MB/s) - \u2018YEAR_2019.csv\u2019 saved [18917414/18917414]\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_2019 = pd.merge(df_2019, df_18, how='inner', on=['ZIP5'])\ndf_2019.shape",
            "execution_count": 12,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 12,
                    "data": {
                        "text/plain": "(302012, 21)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_2019.head()",
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 13,
                    "data": {
                        "text/plain": "      ZIP5    ZIP4  HAS_CHILDREN PRIMARY_LANGUAGE    INCOME  AGE_IN_YEARS  \\\n0  75001.0  3453.0           1.0          English   87500.0     61.902806   \n1  75001.0  3107.0           1.0          English  125000.0     61.232033   \n2  75001.0  5151.0           1.0          English   87500.0     52.736482   \n3  75001.0  6075.0           0.0          English   12500.0     35.397673   \n4  75001.0  4942.0           0.0          English  125000.0     72.150582   \n\n   LENGTH_OF_RESIDENCE HOME_OWNER_RENTER  ACQ  CUSTOMER  ...  ZIP_CUSTOMERS  \\\n0                  2.0                 O    0         0  ...            231   \n1                 11.0                 O    0         0  ...            231   \n2                 15.0                 O    0         0  ...            231   \n3                  1.0                 O    0         0  ...            231   \n4                  6.0                 O    0         0  ...            231   \n\n   ZIP_POPULATION  ZIP_ACQUISITIONS  ZIP_CHURNERS  ZIP_REVENUE  \\\n0             886                62            30        40181   \n1             886                62            30        40181   \n2             886                62            30        40181   \n3             886                62            30        40181   \n4             886                62            30        40181   \n\n   ZIP_PENETRATION_RATE  ZIP_ACQ_RATE  ZIP_CHURN_RATE  ZIP_AVG_REV  \\\n0              0.260722      0.069977         0.12987   173.943723   \n1              0.260722      0.069977         0.12987   173.943723   \n2              0.260722      0.069977         0.12987   173.943723   \n3              0.260722      0.069977         0.12987   173.943723   \n4              0.260722      0.069977         0.12987   173.943723   \n\n   ZIP_MED_REV  \n0        176.0  \n1        176.0  \n2        176.0  \n3        176.0  \n4        176.0  \n\n[5 rows x 21 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ZIP5</th>\n      <th>ZIP4</th>\n      <th>HAS_CHILDREN</th>\n      <th>PRIMARY_LANGUAGE</th>\n      <th>INCOME</th>\n      <th>AGE_IN_YEARS</th>\n      <th>LENGTH_OF_RESIDENCE</th>\n      <th>HOME_OWNER_RENTER</th>\n      <th>ACQ</th>\n      <th>CUSTOMER</th>\n      <th>...</th>\n      <th>ZIP_CUSTOMERS</th>\n      <th>ZIP_POPULATION</th>\n      <th>ZIP_ACQUISITIONS</th>\n      <th>ZIP_CHURNERS</th>\n      <th>ZIP_REVENUE</th>\n      <th>ZIP_PENETRATION_RATE</th>\n      <th>ZIP_ACQ_RATE</th>\n      <th>ZIP_CHURN_RATE</th>\n      <th>ZIP_AVG_REV</th>\n      <th>ZIP_MED_REV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75001.0</td>\n      <td>3453.0</td>\n      <td>1.0</td>\n      <td>English</td>\n      <td>87500.0</td>\n      <td>61.902806</td>\n      <td>2.0</td>\n      <td>O</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>231</td>\n      <td>886</td>\n      <td>62</td>\n      <td>30</td>\n      <td>40181</td>\n      <td>0.260722</td>\n      <td>0.069977</td>\n      <td>0.12987</td>\n      <td>173.943723</td>\n      <td>176.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>75001.0</td>\n      <td>3107.0</td>\n      <td>1.0</td>\n      <td>English</td>\n      <td>125000.0</td>\n      <td>61.232033</td>\n      <td>11.0</td>\n      <td>O</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>231</td>\n      <td>886</td>\n      <td>62</td>\n      <td>30</td>\n      <td>40181</td>\n      <td>0.260722</td>\n      <td>0.069977</td>\n      <td>0.12987</td>\n      <td>173.943723</td>\n      <td>176.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>75001.0</td>\n      <td>5151.0</td>\n      <td>1.0</td>\n      <td>English</td>\n      <td>87500.0</td>\n      <td>52.736482</td>\n      <td>15.0</td>\n      <td>O</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>231</td>\n      <td>886</td>\n      <td>62</td>\n      <td>30</td>\n      <td>40181</td>\n      <td>0.260722</td>\n      <td>0.069977</td>\n      <td>0.12987</td>\n      <td>173.943723</td>\n      <td>176.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75001.0</td>\n      <td>6075.0</td>\n      <td>0.0</td>\n      <td>English</td>\n      <td>12500.0</td>\n      <td>35.397673</td>\n      <td>1.0</td>\n      <td>O</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>231</td>\n      <td>886</td>\n      <td>62</td>\n      <td>30</td>\n      <td>40181</td>\n      <td>0.260722</td>\n      <td>0.069977</td>\n      <td>0.12987</td>\n      <td>173.943723</td>\n      <td>176.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>75001.0</td>\n      <td>4942.0</td>\n      <td>0.0</td>\n      <td>English</td>\n      <td>125000.0</td>\n      <td>72.150582</td>\n      <td>6.0</td>\n      <td>O</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>231</td>\n      <td>886</td>\n      <td>62</td>\n      <td>30</td>\n      <td>40181</td>\n      <td>0.260722</td>\n      <td>0.069977</td>\n      <td>0.12987</td>\n      <td>173.943723</td>\n      <td>176.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 21 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now we can use our features to build an Acquisition Model using ACQ as a dependent variable.  The features should allow us to extract the full predictive value from the zip code field.\n\nOne last note.  When you actually deploy the model to our 2020 data, use the 2019 data to create your zip code feature variables, not 2018.   This makes sense right?  The features are extracted from the most recent year of data.  When we build a model for 2019, this was 2018.   When we deploy the model for 2020, this would be 2019."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Author"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "**Shad Griffin**, is a Data Scientist at the IBM Global Solution Center in Dallas, Texas"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Copyright for Watson Studio community\n\n<hr>\nCopyright &copy; IBM Corp. 2019. This notebook and its source code are released under the terms of the MIT License."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}